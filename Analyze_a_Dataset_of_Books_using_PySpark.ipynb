{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2fAvHOByy5yabhzcTEld4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IsfaquethedataAnalyst/Data_Analyst/blob/main/Analyze_a_Dataset_of_Books_using_PySpark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create a PySpark application that analyzes a dataset of books. We'll perform various operations to extract insights from the data.\n",
        "\n",
        "\n",
        "\n",
        "1.   First, set up your environment:\n",
        "\n",
        "*   Install PySpark\n",
        "*   Create a new Python file, book_analysis.py\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Lfsu8-MhUHeD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQxwJF19VIO6",
        "outputId": "8175d9c5-dfaf-48eb-e2e0-cd9f7bdcea4d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Q0TfNzJBTEKj"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, avg, count, year\n",
        "\n",
        "# Initialize Spark Session\n",
        "spark = SparkSession.builder.appName(\"BookAnalysis\").getOrCreate()\n",
        "\n",
        "# Load the dataset\n",
        "# Assuming you have a CSV file named 'books.csv' with columns: title, author, publication_year, genre, rating\n",
        "df = spark.read.csv(\"Books.csv\", header=True, inferSchema=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_books(df):\n",
        "    pass"
      ],
      "metadata": {
        "id": "_v9d8SUcWddM"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DdtjxXpW05G",
        "outputId": "8c76f246-201b-420b-8ace-afd041cbdabe"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|               Title|             Authors|         Description|            Category|           Publisher|        Publish Date|               Price|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|       Goat Brothers|    By Colton, Larry|                NULL|   History , General|           Doubleday|Friday, January 1...|Price Starting at...|\n",
            "|  The Missing Person|  By Grumbach, Doris|                NULL|   Fiction , General|    Putnam Pub Group|Sunday, March 1, ...|Price Starting at...|\n",
            "|Don't Eat Your He...|By Piscatella, Jo...|                NULL| Cooking , Reference|      Workman Pub Co|Thursday, Septemb...|Price Starting at...|\n",
            "|When Your Corpora...|   By Davis, Paul D.|                NULL|                NULL|       Natl Pr Books|Monday, April 1, ...|Price Starting at...|\n",
            "|Amy Spangler's Br...|    By Spangler, Amy|                NULL|                NULL|        Amy Spangler|Saturday, Februar...|Price Starting at...|\n",
            "|The Foundation of...|        By Short, Bo|                NULL|                NULL|     Excalibur Press|Wednesday, Januar...|Price Starting at...|\n",
            "|Chicken Soup for ...|By Canfield, Jack...|                NULL| Self-help , Pers...|Health Communicat...|Saturday, May 1, ...|Price Starting at...|\n",
            "|Journey Through H...|By Stepanek, Matt...|Collects poems wr...|    Poetry , General|           VSP Books|Saturday, Septemb...|Price Starting at...|\n",
            "|In Search of Mela...|By Aksyonov, Vass...|The Russian autho...| Biography & Auto...|        Random House|Monday, June 1, 1987|Price Starting at...|\n",
            "|   Christmas Cookies|By Eakin, Katheri...|                NULL|   Cooking , General|        Oxmoor House|Sunday, June 1, 1986|Price Starting at...|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "genre_counts = df.groupBy(\"Category\").count().orderBy(col(\"count\").desc())\n",
        "genre_counts.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IWUL-qcXGaG",
        "outputId": "6343a804-9bae-4379-9566-de5d0e4267df"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+\n",
            "|            Category|count|\n",
            "+--------------------+-----+\n",
            "|                NULL|25763|\n",
            "|   Fiction , General| 2208|\n",
            "| Fiction , Myster...| 1390|\n",
            "|  Fiction , Literary| 1302|\n",
            "| Fiction , Romanc...|  943|\n",
            "| Fiction , Thrill...|  903|\n",
            "| Fiction , Thrill...|  878|\n",
            "|  Religion , General|  871|\n",
            "|   Cooking , General|  820|\n",
            "| Fiction , Romanc...|  657|\n",
            "| Fiction , Romanc...|  601|\n",
            "| Fiction , Scienc...|  597|\n",
            "|   History , General|  585|\n",
            "| Juvenile Fiction...|  561|\n",
            "| Juvenile Nonfict...|  538|\n",
            "| Social Science ,...|  526|\n",
            "| Business & Econo...|  525|\n",
            "| Juvenile Fiction...|  438|\n",
            "| Religion , Chris...|  430|\n",
            "|   Science , General|  414|\n",
            "+--------------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avg_price = df.groupBy(\"Category\").agg(avg(\"Price\").alias(\"avg_price\"))\n",
        "avg_price.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hA4_BM3uXhZ6",
        "outputId": "5dd8b558-2038-46a1-e8b9-b92c615d964d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+---------+\n",
            "|            Category|avg_price|\n",
            "+--------------------+---------+\n",
            "|       Art , General|     NULL|\n",
            "| Religion , Judai...|     NULL|\n",
            "| Religion , Bibli...|     NULL|\n",
            "| Fiction , Africa...|     NULL|\n",
            "| Business & Econo...|     NULL|\n",
            "| Political Scienc...|     NULL|\n",
            "| but nevertheless...|     NULL|\n",
            "| Cooking , Region...|     NULL|\n",
            "| Technology & Eng...|     NULL|\n",
            "| Medical , Nursin...|     NULL|\n",
            "|   for mental acuity|     NULL|\n",
            "|    once and for all|     NULL|\n",
            "|            get lean|     NULL|\n",
            "| But That Don't M...|     NULL|\n",
            "|        or mercenary|     NULL|\n",
            "| fans have been f...|     NULL|\n",
            "| acting as his ey...|     NULL|\n",
            "| Medical , Oncolo...|     NULL|\n",
            "| including:* Deve...|     NULL|\n",
            "| knowing and hila...|     NULL|\n",
            "+--------------------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "author_counts = df.groupBy(\"Authors\").count().orderBy(col(\"count\").desc()) # Use \"Authors\" instead of \"author\"\n",
        "author_counts.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuL888IZYM5e",
        "outputId": "f583c4ce-c2da-428b-b475-7bcbdc1ce8ef"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+\n",
            "|             Authors|count|\n",
            "+--------------------+-----+\n",
            "|                  By| 1043|\n",
            "|    By Roberts, Nora|  195|\n",
            "|  By Time-Life Books|  172|\n",
            "|          By unknown|  122|\n",
            "|\"By \"\"Better Home...|  121|\n",
            "|  By Steel, Danielle|  120|\n",
            "|      By Lucado, Max|   97|\n",
            "|              By n/a|   92|\n",
            "|By Reader's Diges...|   89|\n",
            "| By Macomber, Debbie|   85|\n",
            "+--------------------+-----+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "books_per_year = df.groupBy(year(\"Publish Date\").alias(\"year\")).count().orderBy(\"year\")\n",
        "books_per_year.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fd3Ri7v-YfIm",
        "outputId": "004f9374-37e8-4c13-8031-c58dea13906d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+------+\n",
            "|year| count|\n",
            "+----+------+\n",
            "|NULL|103078|\n",
            "|1865|     1|\n",
            "|1955|     1|\n",
            "|1995|     1|\n",
            "|2012|     1|\n",
            "+----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_data(df):\n",
        "  # Implement your data cleaning logic here\n",
        "  # For example, removing duplicates, handling missing values, etc.\n",
        "  return df\n",
        "\n",
        "cleaned_df = clean_data(df)"
      ],
      "metadata": {
        "id": "fEuvP341iIe_"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Basic Statistics:\")\n",
        "cleaned_df.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "in1v7kd6iYID",
        "outputId": "43018ee2-40ce-417c-cd24-91c08613b41f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Basic Statistics:\n",
            "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|summary|               Title|             Authors|         Description|            Category|           Publisher|        Publish Date|               Price|\n",
            "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "|  count|              103082|              103082|               70231|               77319|              103000|              103023|              103041|\n",
            "|   mean|             1310.04|                NULL|                 2.0|              1285.2|  3540556.8493150687|            1046.375|             834.625|\n",
            "| stddev|   864.0054361968898|                NULL|                NULL|    955.917889008421|  3234904.2949715196|   987.1423312485678|   958.2619590398323|\n",
            "|    min| American Heritag...|                14)\"|         Carol Field|      Ellen the prey|   high carbohydr...|           or hunger|   Chang Yu-i's l...|\n",
            "|    max|¿Qué Pasó?: An En...|By zheleznova, irina|﻿Introduction by ...|” this compelling...|” Wolfe's outlaw ...|” who is lucky en...|” chants the boy ...|\n",
            "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import length\n",
        "\n",
        "print(\"Book Length Analysis:\")\n",
        "length_df = cleaned_df.withColumn(\"title_length\", length(col(\"title\")))\n",
        "length_df.select(avg(\"title_length\").alias(\"avg_title_length\")).show()\n",
        "\n",
        "print(\"Top 5 Longest Titles:\")\n",
        "length_df.orderBy(col(\"title_length\").desc()).select(\"title\", \"title_length\").show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfADYaT2jeok",
        "outputId": "a84e2c94-a6ac-4d82-ada1-254cc68a1175"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Book Length Analysis:\n",
            "+------------------+\n",
            "|  avg_title_length|\n",
            "+------------------+\n",
            "|44.744776003569974|\n",
            "+------------------+\n",
            "\n",
            "Top 5 Longest Titles:\n",
            "+--------------------+------------+\n",
            "|               title|title_length|\n",
            "+--------------------+------------+\n",
            "|A Generous Orthod...|         293|\n",
            "|Rules of Contract...|         254|\n",
            "|The Old West Spea...|         248|\n",
            "|Fleeced: How Bara...|         244|\n",
            "|Nineteenth Centur...|         243|\n",
            "+--------------------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Author Productivity Over Time:\")\n",
        "# Verify the column names in your cleaned DataFrame\n",
        "print(cleaned_df.columns)\n",
        "\n",
        "# Assuming the date column is named 'Publish Date' after cleaning\n",
        "author_productivity = cleaned_df.groupBy(\"Authors\", year(\"Publish Date\").alias(\"year\")) \\\n",
        "                               .count() \\\n",
        "                               .orderBy(\"Authors\", \"year\")\n",
        "author_productivity.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjgeMbXaj2pw",
        "outputId": "08ab9bd0-7700-4d13-e5c3-489ade0bf703"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Author Productivity Over Time:\n",
            "['Title', 'Authors', 'Description', 'Category', 'Publisher', 'Publish Date', 'Price']\n",
            "+--------------------+----+-----+\n",
            "|             Authors|year|count|\n",
            "+--------------------+----+-----+\n",
            "|                14)\"|NULL|    1|\n",
            "|          1780-1835\"|NULL|    1|\n",
            "|            Book 3)\"|NULL|    2|\n",
            "| Charlie Brown! V...|NULL|    1|\n",
            "|            Expanded|NULL|    1|\n",
            "| Jr. With researc...|NULL|    1|\n",
            "|           Level 1)\"|NULL|    1|\n",
            "|   Love and Losers.\"|NULL|    1|\n",
            "| Maintain and Ach...|NULL|    1|\n",
            "| More Peanuts! Vo...|NULL|    1|\n",
            "| Plain and Tall\"\"...|NULL|    1|\n",
            "| Proverbs 20:17 (...|NULL|    1|\n",
            "|           Saving It|NULL|    1|\n",
            "| Sexuality and Su...|NULL|    1|\n",
            "| Shed Pounds for ...|NULL|    1|\n",
            "|               The)\"|NULL|    1|\n",
            "| Together with Da...|NULL|    1|\n",
            "|            Vol. 4)\"|NULL|    1|\n",
            "|            Vol. 9)\"|NULL|    1|\n",
            "|                   \"|NULL|    1|\n",
            "+--------------------+----+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}